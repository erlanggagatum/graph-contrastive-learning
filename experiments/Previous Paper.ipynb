{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import networkx\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch.nn import CosineSimilarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation on MUTAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(root=\"../dataset\", name='MUTAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      " tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]])\n",
      "Complementary:\n",
      " tensor([[[0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "         [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.],\n",
      "         [0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "adj_o = to_dense_adj(dataset[2].edge_index)\n",
    "adj_c = abs(to_dense_adj(dataset[2].edge_index) - 1) - torch.eye(len(dataset[2].x))\n",
    "\n",
    "print(\"Original:\\n\", adj_o)\n",
    "print(\"Complementary:\\n\", (adj_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toComplementary(g):\n",
    "    c = abs(to_dense_adj(g.edge_index) - 1) - torch.eye(len(g.x))\n",
    "    c = c[0].nonzero().t().contiguous()\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_c = []\n",
    "for graph in dataset:\n",
    "    edge_c = toComplementary(graph)\n",
    "    dataset_c.append(Data(edge_index=edge_c, x=graph.x, y=graph.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "        0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "ys = []\n",
    "for d in dataset_c:\n",
    "    ys.append(d.y.item())\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "ratio = 0.8\n",
    "total = len(dataset)\n",
    "\n",
    "# original graph\n",
    "g_train = dataset[:round(ratio*total)]\n",
    "g_test = dataset[round(ratio*total):]\n",
    "\n",
    "# complementary graph\n",
    "gc_train = dataset_c[:round(ratio*total)]\n",
    "gc_test = dataset_c[round(ratio*total):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_train MUTAG(150)\n",
      "g_test MUTAG(38)\n",
      "gc_train 150\n",
      "gc_test 38\n"
     ]
    }
   ],
   "source": [
    "print(f'g_train {g_train}')\n",
    "print(f'g_test {g_test}')\n",
    "print(f'gc_train {len(gc_train)}')\n",
    "print(f'gc_test {len(gc_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print([x.y.item() for x in g_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print([x.y.item() for x in gc_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "seed = 12345\n",
    "\n",
    "g_train_loader = DataLoader(g_train, batch_size=bs, shuffle=False)\n",
    "g_test_loader = DataLoader(g_test, batch_size=bs, shuffle=False)\n",
    "\n",
    "gc_train_loader = DataLoader(gc_train, batch_size=bs, shuffle=False)\n",
    "gc_test_loader = DataLoader(gc_test, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 1])\n",
      "tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "for g in g_train_loader:\n",
    "    print(g.y)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for g in g_test_loader:\n",
    "    print(g.y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 1])\n",
      "tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "for g in gc_train_loader:\n",
    "    print(g.y)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for g in gc_test_loader:\n",
    "    print(g.y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import global_max_pool\n",
    "from torch_geometric.nn import global_add_pool\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplementarySupCon(torch.nn.Module):\n",
    "    def __init__(self, dataset, hidden_channels):\n",
    "        super(ComplementarySupCon, self).__init__()\n",
    "        \n",
    "        # weight seed\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1_o = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2_o = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        self.conv1_c = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2_c = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        # classification layer\n",
    "        # self.lin1 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x_o, x_c, edge_index_o, edge_index_c, batch_o):\n",
    "        x_o = self.conv1_o(x_o, edge_index_o)\n",
    "        x_o = x_o.relu()\n",
    "        x_o = self.conv2_o(x_o, edge_index_o)\n",
    "        \n",
    "        x_c = self.conv1_c(x_c, edge_index_c)\n",
    "        x_c = x_c.relu()\n",
    "        x_c = self.conv2_c(x_c, edge_index_c)\n",
    "\n",
    "\n",
    "        h = (x_o + x_c)/2\n",
    "        h = global_add_pool(h, batch_o)\n",
    "        \n",
    "        # h.relu()\n",
    "        h = self.lin(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, g_loader, gc_loader, classification = False):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    \n",
    "    for _, (g_o, g_c) in enumerate(zip(g_loader, gc_loader)):\n",
    "        h = model(g_o.x, g_c.x, g_o.edge_index, g_c.edge_index, g_o.batch)\n",
    "        loss = criterion(h, g_o.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    return h, loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, g_loader, gc_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for _, (g_o, g_c) in enumerate(zip(g_loader, gc_loader)):\n",
    "        z = model(g_o.x, g_c.x, g_o.edge_index, g_c.edge_index, g_o.batch)\n",
    "        pred = z.argmax(dim=1)\n",
    "        correct += int((pred == g_o.y).sum())\n",
    "\n",
    "    return correct/len(g_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ComplementarySupCon(dataset, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 1.6808 accuracy: 0.6842\n",
      "epoch: 2 loss: 0.6577 accuracy: 0.3158\n",
      "epoch: 3 loss: 0.7700 accuracy: 0.3158\n",
      "epoch: 4 loss: 0.9265 accuracy: 0.6842\n",
      "epoch: 5 loss: 0.6739 accuracy: 0.3158\n",
      "epoch: 6 loss: 0.9625 accuracy: 0.6842\n",
      "epoch: 7 loss: 0.6392 accuracy: 0.3158\n",
      "epoch: 8 loss: 1.0295 accuracy: 0.6842\n",
      "epoch: 9 loss: 0.6415 accuracy: 0.6842\n",
      "epoch: 10 loss: 0.6401 accuracy: 0.3158\n",
      "epoch: 11 loss: 1.0641 accuracy: 0.6842\n",
      "epoch: 12 loss: 0.6457 accuracy: 0.6842\n",
      "epoch: 13 loss: 0.6627 accuracy: 0.3158\n",
      "epoch: 14 loss: 1.0875 accuracy: 0.6842\n",
      "epoch: 15 loss: 0.6765 accuracy: 0.5000\n",
      "epoch: 16 loss: 0.8766 accuracy: 0.7105\n",
      "epoch: 17 loss: 0.6953 accuracy: 0.3158\n",
      "epoch: 18 loss: 1.1732 accuracy: 0.6842\n",
      "epoch: 19 loss: 0.8668 accuracy: 0.6842\n",
      "epoch: 20 loss: 0.7010 accuracy: 0.3158\n",
      "epoch: 21 loss: 1.1579 accuracy: 0.7105\n",
      "epoch: 22 loss: 0.7146 accuracy: 0.7632\n",
      "epoch: 23 loss: 0.8840 accuracy: 0.7105\n",
      "epoch: 24 loss: 0.8049 accuracy: 0.6316\n",
      "epoch: 25 loss: 0.8800 accuracy: 0.7632\n",
      "epoch: 26 loss: 0.8439 accuracy: 0.6316\n",
      "epoch: 27 loss: 1.0248 accuracy: 0.7105\n",
      "epoch: 28 loss: 0.7866 accuracy: 0.2895\n",
      "epoch: 29 loss: 1.3186 accuracy: 0.6579\n",
      "epoch: 30 loss: 0.9982 accuracy: 0.6842\n",
      "epoch: 31 loss: 0.8286 accuracy: 0.3421\n",
      "epoch: 32 loss: 1.1227 accuracy: 0.6579\n",
      "epoch: 33 loss: 0.8780 accuracy: 0.7105\n",
      "epoch: 34 loss: 0.8026 accuracy: 0.2895\n",
      "epoch: 35 loss: 1.4025 accuracy: 0.6579\n",
      "epoch: 36 loss: 0.9278 accuracy: 0.7105\n",
      "epoch: 37 loss: 0.8705 accuracy: 0.7105\n",
      "epoch: 38 loss: 1.0361 accuracy: 0.6842\n",
      "epoch: 39 loss: 0.8946 accuracy: 0.3158\n",
      "epoch: 40 loss: 1.3660 accuracy: 0.6579\n",
      "epoch: 41 loss: 1.0683 accuracy: 0.6842\n",
      "epoch: 42 loss: 0.9029 accuracy: 0.2632\n",
      "epoch: 43 loss: 1.3117 accuracy: 0.6316\n",
      "epoch: 44 loss: 1.0058 accuracy: 0.7105\n",
      "epoch: 45 loss: 0.9791 accuracy: 0.6842\n",
      "epoch: 46 loss: 1.1444 accuracy: 0.7105\n",
      "epoch: 47 loss: 1.0038 accuracy: 0.2895\n",
      "epoch: 48 loss: 1.4530 accuracy: 0.6579\n",
      "epoch: 49 loss: 1.1687 accuracy: 0.6842\n",
      "epoch: 50 loss: 0.9431 accuracy: 0.4211\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 50):\n",
    "    h, loss = train(model, g_train_loader, gc_train_loader)\n",
    "    acc = test(model, g_test_loader, gc_test_loader)\n",
    "    print(f\"epoch: {epoch+1} loss: {loss:.4f} accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
