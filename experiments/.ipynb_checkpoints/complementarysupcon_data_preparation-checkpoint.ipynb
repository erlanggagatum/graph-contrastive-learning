{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import networkx\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_dense_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation on MUTAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(root=\"../dataset\", name='MUTAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      " tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]])\n",
      "Complementary:\n",
      " tensor([[[0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "         [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.],\n",
      "         [0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "adj_o = to_dense_adj(dataset[2].edge_index)\n",
    "adj_c = abs(to_dense_adj(dataset[2].edge_index) - 1) - torch.eye(len(dataset[2].x))\n",
    "\n",
    "print(\"Original:\\n\", adj_o)\n",
    "print(\"Complementary:\\n\", (adj_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toComplementary(g):\n",
    "    c = abs(to_dense_adj(g.edge_index) - 1) - torch.eye(len(g.x))\n",
    "    c = c[0].nonzero().t().contiguous()\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_c = []\n",
    "for graph in dataset:\n",
    "    edge_c = toComplementary(graph)\n",
    "    dataset_c.append(Data(edge_index=edge_c, x=graph.x, y=graph.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "        0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "ys = []\n",
    "for d in dataset_c:\n",
    "    ys.append(d.y.item())\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "ratio = 0.5\n",
    "total = len(dataset)\n",
    "\n",
    "# original graph\n",
    "g_train = dataset[:round(ratio*total)]\n",
    "g_test = dataset[round(ratio*total):]\n",
    "\n",
    "# complementary graph\n",
    "gc_train = dataset_c[:round(ratio*total)]\n",
    "gc_test = dataset_c[round(ratio*total):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_train MUTAG(94)\n",
      "g_test MUTAG(94)\n",
      "gc_train 94\n",
      "gc_test 94\n"
     ]
    }
   ],
   "source": [
    "print(f'g_train {g_train}')\n",
    "print(f'g_test {g_test}')\n",
    "print(f'gc_train {len(gc_train)}')\n",
    "print(f'gc_test {len(gc_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print([x.y.item() for x in g_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print([x.y.item() for x in gc_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "seed = 12345\n",
    "\n",
    "g_train_loader = DataLoader(g_train, batch_size=bs, shuffle=False)\n",
    "g_test_loader = DataLoader(g_test, batch_size=bs, shuffle=False)\n",
    "\n",
    "gc_train_loader = DataLoader(gc_train, batch_size=bs, shuffle=False)\n",
    "gc_test_loader = DataLoader(gc_test, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 1])\n",
      "tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for g in g_train_loader:\n",
    "    print(g.y)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for g in g_test_loader:\n",
    "    print(g.y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 1])\n",
      "tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for g in gc_train_loader:\n",
    "    print(g.y)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for g in gc_test_loader:\n",
    "    print(g.y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import global_max_pool\n",
    "from torch_geometric.nn import global_add_pool\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplementarySupCon(torch.nn.Module):\n",
    "    def __init__(self, dataset, hidden_channels):\n",
    "        super(ComplementarySupCon, self).__init__()\n",
    "        \n",
    "        # weight seed\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1_o = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2_o = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        self.conv1_c = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2_c = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x_o, x_c, edge_index_o, edge_index_c, batch_o, batch_c):\n",
    "        x_o = self.conv1_o(x_o, edge_index_o)\n",
    "        x_o = x_o.relu()\n",
    "        x_o = self.conv2_o(x_o, edge_index_o)\n",
    "        \n",
    "        x_c = self.conv1_o(x_c, edge_index_c)\n",
    "        x_c = x_c.relu()\n",
    "        x_c = self.conv2_o(x_c, edge_index_c)\n",
    "\n",
    "        h = x_o - x_c\n",
    "        \n",
    "        h = global_add_pool(h, batch_o)\n",
    "        \n",
    "        return h, x_o, x_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ComplementarySupCon(dataset, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementarySupCon(\n",
       "  (conv1_o): GCNConv(7, 64)\n",
       "  (conv2_o): GCNConv(64, 64)\n",
       "  (conv1_c): GCNConv(7, 64)\n",
       "  (conv2_c): GCNConv(64, 64)\n",
       ")"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, x_o, x_c = None, None, None\n",
    "for index, (g_o, g_c) in enumerate(zip(g_train_loader, gc_train_loader)):\n",
    "    h, x_o, x_c = (model(g_o.x, g_c.x, g_o.edge_index, g_c.edge_index, g_o.batch, g_c.batch))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([585, 64])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([585, 7])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_o.x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "         4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,\n",
       "         8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "         9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "        11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "        16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "        17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19,\n",
       "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21,\n",
       "        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22,\n",
       "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
       "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
       "        23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n",
       "        24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,\n",
       "        26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "        27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "        28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29,\n",
       "        29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30,\n",
       "        30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "        30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31,\n",
       "        31, 31, 31, 31, 31, 31, 31, 31, 31])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_o.batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
